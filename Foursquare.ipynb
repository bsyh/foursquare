{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Foursquare.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bsyh/foursquare/blob/main/Foursquare.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 团队版本\n",
        "https://github.com/bsyh/foursquare\n"
      ],
      "metadata": {
        "id": "eDId5Z6xIyz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "access to google drive"
      ],
      "metadata": {
        "id": "a-5I7_lMHOaE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fNr0YFB_EQoj",
        "outputId": "e213ca80-b294-4e99-b89a-90052622a3ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root_path = 'drive/MyDrive/Foursquare/'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "create path"
      ],
      "metadata": {
        "id": "XWcin6lWHGYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess, os, sys, ipykernel\n",
        "\n",
        "def wget(url, outputdir):\n",
        "  res = subprocess.run(['wget', url, '-P', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "  print(res)\n",
        "\n",
        "def createPath(filepath):\n",
        "  os.makedirs(filepath, exist_ok=True)\n",
        "\n",
        "data_path = f'{root_path}/data'\n",
        "createPath(data_path)\n",
        "\n",
        "out_path = f'{root_path}/out'\n",
        "createPath(out_path)\n"
      ],
      "metadata": {
        "id": "vjgxfIUnHJwg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "download dataset"
      ],
      "metadata": {
        "id": "pBCqIivrMtt5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "#@markdown If you don't want the dataset be downloaded, uncheck the box:\n",
        "download_dataset = False #@param{type:\"boolean\"}\n",
        "\n",
        "if download_dataset:\n",
        "  !pip install gdown\n",
        "  !cd f'{data_path}'\n",
        "  !gdown --folder https://drive.google.com/drive/folders/1-8C3oY9dLErVL3zCteWayKg9x_ALjGlT"
      ],
      "metadata": {
        "id": "3dduUvhaMyZB"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "importimport packages"
      ],
      "metadata": {
        "id": "t2qSnfs0GpVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "YNw4JbWWW5ik"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(f'{data_path}/train.csv')\n",
        "test = pd.read_csv(f'{data_path}/test.csv')\n",
        "pd.options.display.max_rows,pd.options.display.max_columns = 1000,14 # display all rows annd columns\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "jj9GkKH3W5rJ",
        "outputId": "139f6253-7577-4f02-ce35-23aab70dc14c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 id                     name   latitude   longitude  \\\n",
              "0  E_000001272c6c5d     Café Stad Oudenaarde  50.859975    3.634196   \n",
              "1  E_000002eae2a589           Carioca Manero -22.907225  -43.178244   \n",
              "2  E_000007f24ebc95         ร้านตัดผมการาเกด  13.780813  100.484900   \n",
              "3  E_000008a8ba4f48                 Turkcell  37.844510   27.844202   \n",
              "4  E_00001d92066153  Restaurante Casa Cofiño  43.338196   -4.326821   \n",
              "\n",
              "                  address        city            state   zip country  url  \\\n",
              "0             Abdijstraat  Nederename  Oost-Vlaanderen  9700      BE  NaN   \n",
              "1                     NaN         NaN              NaN   NaN      BR  NaN   \n",
              "2                     NaN         NaN              NaN   NaN      TH  NaN   \n",
              "3  Adnan Menderes Bulvarı         NaN              NaN   NaN      TR  NaN   \n",
              "4                     NaN    Caviedes        Cantabria   NaN      ES  NaN   \n",
              "\n",
              "  phone             categories point_of_interest  \n",
              "0   NaN                   Bars  P_677e840bb6fc7e  \n",
              "1   NaN  Brazilian Restaurants  P_d82910d8382a83  \n",
              "2   NaN   Salons / Barbershops  P_b1066599e78477  \n",
              "3   NaN     Mobile Phone Shops  P_b2ed86905a4cd3  \n",
              "4   NaN    Spanish Restaurants  P_809a884d4407fb  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fc0734c6-4ec5-458e-ba33-9319cdc0068a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitude</th>\n",
              "      <th>address</th>\n",
              "      <th>city</th>\n",
              "      <th>state</th>\n",
              "      <th>zip</th>\n",
              "      <th>country</th>\n",
              "      <th>url</th>\n",
              "      <th>phone</th>\n",
              "      <th>categories</th>\n",
              "      <th>point_of_interest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>E_000001272c6c5d</td>\n",
              "      <td>Café Stad Oudenaarde</td>\n",
              "      <td>50.859975</td>\n",
              "      <td>3.634196</td>\n",
              "      <td>Abdijstraat</td>\n",
              "      <td>Nederename</td>\n",
              "      <td>Oost-Vlaanderen</td>\n",
              "      <td>9700</td>\n",
              "      <td>BE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Bars</td>\n",
              "      <td>P_677e840bb6fc7e</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E_000002eae2a589</td>\n",
              "      <td>Carioca Manero</td>\n",
              "      <td>-22.907225</td>\n",
              "      <td>-43.178244</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>BR</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Brazilian Restaurants</td>\n",
              "      <td>P_d82910d8382a83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>E_000007f24ebc95</td>\n",
              "      <td>ร้านตัดผมการาเกด</td>\n",
              "      <td>13.780813</td>\n",
              "      <td>100.484900</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TH</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Salons / Barbershops</td>\n",
              "      <td>P_b1066599e78477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>E_000008a8ba4f48</td>\n",
              "      <td>Turkcell</td>\n",
              "      <td>37.844510</td>\n",
              "      <td>27.844202</td>\n",
              "      <td>Adnan Menderes Bulvarı</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>TR</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Mobile Phone Shops</td>\n",
              "      <td>P_b2ed86905a4cd3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>E_00001d92066153</td>\n",
              "      <td>Restaurante Casa Cofiño</td>\n",
              "      <td>43.338196</td>\n",
              "      <td>-4.326821</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Caviedes</td>\n",
              "      <td>Cantabria</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ES</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Spanish Restaurants</td>\n",
              "      <td>P_809a884d4407fb</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc0734c6-4ec5-458e-ba33-9319cdc0068a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fc0734c6-4ec5-458e-ba33-9319cdc0068a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fc0734c6-4ec5-458e-ba33-9319cdc0068a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7uG6akuRW5uX",
        "outputId": "cafd997a-c740-4e77-9550-011dd3b5c858"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1138812 entries, 0 to 1138811\n",
            "Data columns (total 13 columns):\n",
            " #   Column             Non-Null Count    Dtype  \n",
            "---  ------             --------------    -----  \n",
            " 0   id                 1138812 non-null  object \n",
            " 1   name               1138811 non-null  object \n",
            " 2   latitude           1138812 non-null  float64\n",
            " 3   longitude          1138812 non-null  float64\n",
            " 4   address            742191 non-null   object \n",
            " 5   city               839623 non-null   object \n",
            " 6   state              718226 non-null   object \n",
            " 7   zip                543386 non-null   object \n",
            " 8   country            1138801 non-null  object \n",
            " 9   url                267724 non-null   object \n",
            " 10  phone              342855 non-null   object \n",
            " 11  categories         1040505 non-null  object \n",
            " 12  point_of_interest  1138812 non-null  object \n",
            "dtypes: float64(2), object(11)\n",
            "memory usage: 112.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "D:"
      ],
      "metadata": {
        "id": "YaQnky8fiayC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tgin7t4ky7s",
        "outputId": "79bde6f7-2d2e-4414-e26a-1bcd4cb4d5c5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.64.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.96)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.20.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.11.0+cu113)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.7)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.12.0+cu113)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (3.0.9)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.6.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (3.1.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import RobertaTokenizer, RobertaModel\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
        "model = RobertaModel.from_pretrained('roberta-base')"
      ],
      "metadata": {
        "id": "djDd9c3viaOR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4636ba61-c70f-429e-9b91-2cabaf70d2de"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.fillna(\"\")\n",
        "text = train[\"name\"]+ '[sep]' + train['address'] + '[sep]' + train['city'] + '[sep]' + train['state'] + '[sep]' + train['country'] + '[sep]' + train['url'] + '[sep]' + train['categories']\n",
        "text"
      ],
      "metadata": {
        "id": "Cc8Hq7nb3IrG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c71e2766-0a16-4a2e-c05f-ba991355da96"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          Café Stad Oudenaarde[sep]Abdijstraat[sep]Neder...\n",
              "1          Carioca Manero[sep][sep][sep][sep]BR[sep][sep]...\n",
              "2          ร้านตัดผมการาเกด[sep][sep][sep][sep]TH[sep][se...\n",
              "3          Turkcell[sep]Adnan Menderes Bulvarı[sep][sep][...\n",
              "4          Restaurante Casa Cofiño[sep][sep]Caviedes[sep]...\n",
              "                                 ...                        \n",
              "1138807           青ガエル[sep][sep]渋谷区[sep]東京都[sep]JP[sep][sep]\n",
              "1138808    Deshon Place[sep]325 New Castle Rd[sep]Butler[...\n",
              "1138809    İzmir Adnan Menderes Havaalanı[sep][sep]İzmir[...\n",
              "1138810    焼肉 和家[sep]上野6-13-6[sep]Taitō[sep]東京都[sep]JP[se...\n",
              "1138811    Waihi Beach[sep][sep]Waihi Beach[sep]Bay Of Pl...\n",
              "Length: 1138812, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp = text.tolist()\n",
        "encoded_input = tokenizer(tmp[0],return_tensors='pt')\n",
        "\n",
        "print(encoded_input)\n",
        "output = model(**encoded_input)\n",
        "# return output\n",
        "encoded_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr0FRZUxoij9",
        "outputId": "77e0804a-753f-4eff-83c2-01c62e2a78b4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': tensor([[    0,   347,  2001,  1140,   312,   625,   384,  1906,  4242, 19043,\n",
            "         10975,  1090,   642,   742, 13112,   417,  2161, 10750,   415, 10975,\n",
            "          1090,   642,   742,   487,   196,  2816, 13650, 10975,  1090,   642,\n",
            "           742,   673,  2603,    12,   846,  2560,   463,  8663, 10975,  1090,\n",
            "           642,   742,  8827, 10975,  1090,   642, 46386,  1090,   642,   742,\n",
            "           387,  2726,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "         1, 1, 1, 1, 1]])}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    0,   347,  2001,  1140,   312,   625,   384,  1906,  4242, 19043,\n",
              "         10975,  1090,   642,   742, 13112,   417,  2161, 10750,   415, 10975,\n",
              "          1090,   642,   742,   487,   196,  2816, 13650, 10975,  1090,   642,\n",
              "           742,   673,  2603,    12,   846,  2560,   463,  8663, 10975,  1090,\n",
              "           642,   742,  8827, 10975,  1090,   642, 46386,  1090,   642,   742,\n",
              "           387,  2726,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing & Feature transformation:\n",
        "\n",
        "1. location (latitude, longtitude): finding the nearest several points accroding to distance.\n",
        "2. group of words (name, address, categories): lowercasing, ...\n"
      ],
      "metadata": {
        "id": "dkxEgv9DXYDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. location\n",
        "# calculating nearest points accroding to distance\n",
        "neighbor = NearestNeighbors(n_neighbors=2, metric=\"haversine\", n_jobs=-1) # haversine: 2 arcsin(sqrt(sin^2(0.5*dx) + cos(x1)cos(x2)sin^2(0.5*dy)))\n",
        "position = train.iloc[:,2:4]\n",
        "neighbor.fit(position)\n",
        "distance = neighbor.kneighbors(position)[0]\n",
        "cloest_pos = neighbor.kneighbors(position)[1]"
      ],
      "metadata": {
        "id": "V9972qpFW5wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook shows how to solve the problem as a multi-class classification by finding candidate points based on geographic location.\n",
        "Similarity as a string, such as edit distance and LCS (Longest Common Subsequence), was used for the features of the candidate points.\n",
        "\n",
        "Inference is made on test data only, but the code for training is left commented out.\n",
        "\n",
        "In addition, making the matches bidirectional as a post-processing step improved the score by about 1%."
      ],
      "metadata": {
        "id": "upY06EiRIxkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import gc\n",
        "import random\n",
        "from glob import glob\n",
        "from sklearn.model_selection import GroupKFold, KFold, StratifiedKFold\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import sys\n",
        "from requests import get\n",
        "import multiprocessing\n",
        "import joblib\n",
        "\n",
        "class CFG:\n",
        "    seed = 46\n",
        "    target = \"point_of_interest\"\n",
        "    n_neighbors = 10\n",
        "    n_splits = 3\n",
        "\n",
        "    expID = \"\"\n",
        "    if \"google.colab\" in sys.modules:\n",
        "        expID = get(\"http://172.28.0.2:9000/api/sessions\").json()[0][\"name\"].split(\".\")[0]\n",
        "\n",
        "random.seed(CFG.seed)\n",
        "os.environ[\"PYTHONHASHSEED\"] = str(CFG.seed)\n",
        "np.random.seed(CFG.seed)\n",
        "\n",
        "plt.rcParams[\"font.size\"] = 13\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# %cd /content/drive/MyDrive/kaggle/foursquare-location-matching/{CFG.expID}\n"
      ],
      "metadata": {
        "id": "BjKZSXL2Egwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train = pd.read_csv(\"drive/MyDrive/Foursquare/train.csv\")\n",
        "test = pd.read_csv(\"drive/MyDrive/Foursquare/test.csv\")\n",
        "test[CFG.target] = \"TEST\"\n",
        "\n",
        "train.head(1)"
      ],
      "metadata": {
        "id": "TMjza1MjEvd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "gL8VB6JQNMWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Devide Train Data into about 600K×2"
      ],
      "metadata": {
        "id": "xbOS7nzqI96i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kf = GroupKFold(n_splits=2)\n",
        "for i, (trn_idx, val_idx) in enumerate(kf.split(train, train[CFG.target], train[CFG.target])):\n",
        "    train.loc[val_idx, \"set\"] = i\n",
        "train[\"set\"].value_counts()"
      ],
      "metadata": {
        "id": "AUqL4RBzISFf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Search Candidates"
      ],
      "metadata": {
        "id": "kMKb7IIZJATv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "def add_neighbor_features(df):\n",
        "    dfs = []\n",
        "    columns = ['id', 'name', 'address', 'city', 'state',\n",
        "           'zip', 'country', 'url', 'phone', 'categories']\n",
        "    for c in columns:\n",
        "        if c != \"id\":\n",
        "            df[c] = df[c].astype(str).str.lower()\n",
        "\n",
        "    for country, country_df in tqdm(df.groupby(\"country\")):\n",
        "        country_df = country_df.reset_index(drop=True)\n",
        "        \n",
        "        knn = KNeighborsRegressor(n_neighbors=min(len(country_df), CFG.n_neighbors), \n",
        "                                  metric='haversine', n_jobs=-1)\n",
        "        knn.fit(country_df[['latitude','longitude']], country_df.index)\n",
        "        dists, nears = knn.kneighbors(country_df[['latitude','longitude']], return_distance=True)\n",
        "\n",
        "        targets = country_df[CFG.target].values\n",
        "        for i in range(min(len(country_df), CFG.n_neighbors)):\n",
        "            country_df[f\"d_near_{i}\"] = dists[:, i]\n",
        "            country_df[f\"near_target_{i}\"] = targets[nears[:, i]]\n",
        "            for c in columns:\n",
        "                country_df[f\"near_{c}_{i}\"] = country_df[c].values[nears[:, i]]\n",
        "\n",
        "        for i in range(min(len(country_df), CFG.n_neighbors), CFG.n_neighbors):\n",
        "            country_df[f\"d_near_{i}\"] = np.nan\n",
        "            country_df[f\"near_target_{i}\"] = np.nan\n",
        "            for c in columns:\n",
        "                country_df[f\"near_{c}_{i}\"] = np.nan\n",
        "\n",
        "        dfs.append(country_df)\n",
        "    df = pd.concat(dfs).reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "train = pd.concat([\n",
        "    add_neighbor_features(train[train[\"set\"]==0]), \n",
        "    add_neighbor_features(train[train[\"set\"]==1]), \n",
        "])\n",
        "test = add_neighbor_features(test)\n",
        "\n",
        "train.head(1)"
      ],
      "metadata": {
        "id": "HFzV4htEIXW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Target"
      ],
      "metadata": {
        "id": "yEDDJMsAJC7C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(CFG.n_neighbors):\n",
        "    train.loc[train[CFG.target]==train[f\"near_target_{i}\"], \"target\"] = i\n",
        "train.head()"
      ],
      "metadata": {
        "id": "mzB83s2NIbh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check Maximum Score"
      ],
      "metadata": {
        "id": "iOlYa63PJF_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://www.kaggle.com/code/columbia2131/foursquare-iou-metrics\n",
        "def get_id2poi(input_df: pd.DataFrame) -> dict:\n",
        "    return dict(zip(input_df['id'], input_df['point_of_interest']))\n",
        "\n",
        "def get_poi2ids(input_df: pd.DataFrame) -> dict:\n",
        "    return input_df.groupby('point_of_interest')['id'].apply(set).to_dict()\n",
        "\n",
        "def get_score(input_df: pd.DataFrame):\n",
        "    scores = []\n",
        "    for id_str, matches in zip(input_df['id'].to_numpy(), input_df['matches'].to_numpy()):\n",
        "        targets = poi2ids[id2poi[id_str]]\n",
        "        preds = set(matches.split())\n",
        "        score = len((targets & preds)) / len((targets | preds))\n",
        "        scores.append(score)\n",
        "    scores = np.array(scores)\n",
        "    return scores.mean()\n",
        "\n",
        "id2poi = get_id2poi(train)\n",
        "poi2ids = get_poi2ids(train)"
      ],
      "metadata": {
        "id": "nbmc_RdcIdyp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "\n",
        "train[\"matches\"] = \"\"\n",
        "for i in tqdm(range(CFG.n_neighbors)):\n",
        "    idx = train[CFG.target]==train[f\"near_target_{i}\"]\n",
        "    train.loc[idx, \"matches\"] += \" \" + train.loc[idx, f\"near_id_{i}\"]\n",
        "    scores.append(get_score(train))\n",
        "train[\"mathces\"] = None"
      ],
      "metadata": {
        "id": "xLoMyYsfIfVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(8, 3), facecolor=\"white\")\n",
        "plt.plot(range(CFG.n_neighbors), scores, marker=\"o\")\n",
        "plt.grid()\n",
        "plt.xlabel(\"# of candidates\")\n",
        "plt.ylabel(\"Maximum Score\")\n",
        "plt.ylim([0.6, 1.0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ftWMmQeMIg3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del train\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "nNXAQA_jIib5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}